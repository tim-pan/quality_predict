{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import math\n",
    "from sklearn.ensemble import AdaBoostRegressor as adaboost\n",
    "import sklearn.preprocessing as preprocess\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy.stats as stats\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "import joblib\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor as lgbmr\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge, SGDRegressor, LinearRegression, PassiveAggressiveRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor as nn\n",
    "\n",
    "# %matplotlib notebook\n",
    "#補缺失值=>onehotencoding=>normalize=>observation(remove outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = joblib.load('data/X_train.pkl')\n",
    "y = joblib.load('data/y_train.pkl')\n",
    "\n",
    "X_test = joblib.load('data/X_test.pkl')\n",
    "# y_test = joblib.load('data/y_test.pkl')\n",
    "# feat_select1_1 = joblib.load(f'saved_model_CIEX/feat_columns__stacking1.pkl')\n",
    "\n",
    "X.drop(3231, inplace = True)\n",
    "X.reset_index(drop=True, inplace = True)\n",
    "y.drop(3231, inplace = True)\n",
    "y.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIEX</th>\n",
       "      <th>CIEY</th>\n",
       "      <th>CIEX_DIFF</th>\n",
       "      <th>CIEY_DIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.138889</td>\n",
       "      <td>2.161998</td>\n",
       "      <td>0.00310</td>\n",
       "      <td>0.00310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.139217</td>\n",
       "      <td>2.162539</td>\n",
       "      <td>0.00355</td>\n",
       "      <td>0.00250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.139260</td>\n",
       "      <td>2.161272</td>\n",
       "      <td>0.00660</td>\n",
       "      <td>0.00460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.133462</td>\n",
       "      <td>2.159586</td>\n",
       "      <td>0.00445</td>\n",
       "      <td>0.00220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134885</td>\n",
       "      <td>2.160474</td>\n",
       "      <td>0.00475</td>\n",
       "      <td>0.00220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>0.733000</td>\n",
       "      <td>4.750889</td>\n",
       "      <td>0.00320</td>\n",
       "      <td>0.00265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>0.732655</td>\n",
       "      <td>4.751256</td>\n",
       "      <td>0.00270</td>\n",
       "      <td>0.00275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>0.732672</td>\n",
       "      <td>4.751435</td>\n",
       "      <td>0.00285</td>\n",
       "      <td>0.00265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>0.732709</td>\n",
       "      <td>4.751304</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.00255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>0.732784</td>\n",
       "      <td>4.751198</td>\n",
       "      <td>0.00270</td>\n",
       "      <td>0.00335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4962 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CIEX      CIEY  CIEX_DIFF  CIEY_DIFF\n",
       "0     3.138889  2.161998    0.00310    0.00310\n",
       "1     3.139217  2.162539    0.00355    0.00250\n",
       "2     3.139260  2.161272    0.00660    0.00460\n",
       "3     3.133462  2.159586    0.00445    0.00220\n",
       "4     3.134885  2.160474    0.00475    0.00220\n",
       "...        ...       ...        ...        ...\n",
       "4957  0.733000  4.750889    0.00320    0.00265\n",
       "4958  0.732655  4.751256    0.00270    0.00275\n",
       "4959  0.732672  4.751435    0.00285    0.00265\n",
       "4960  0.732709  4.751304    0.00295    0.00255\n",
       "4961  0.732784  4.751198    0.00270    0.00335\n",
       "\n",
       "[4962 rows x 4 columns]"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pao/Documents/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:4196: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "def find_cc_feat(X, y, num):\n",
    "    cont_type = X.columns\n",
    "    coef_dict = {}\n",
    "    select_feat = []\n",
    "    for i in cont_type:\n",
    "\n",
    "        X_data = X[i].to_numpy()\n",
    "        y_data = y.iloc[:, [0]].to_numpy().reshape(-1,)\n",
    "        coef, pvalue = stats.spearmanr(X_data, y_data)\n",
    "\n",
    "        bad = ~np.logical_or(np.isnan(coef), np.isnan(pvalue))\n",
    "\n",
    "    #     print(bad)\n",
    "        if bad == False:\n",
    "            X.drop(columns=i, inplace=False)\n",
    "    #Note that if you get a weird pvalue, \n",
    "    # https://www.zhihu.com/question/22114982\n",
    "    #i dont use sperman(? cause i am lazy, so the pvalue is only as reference\n",
    "        elif bad == True and pvalue <= 0.05:\n",
    "            coef_dict[i] = np.abs(coef)\n",
    "#             print(f'column:{i:10s}, correlation coefficient:{coef:7.4f}, test correlation pvalue output:{pvalue:2.4f}' )\n",
    "        elif bad == True and pvalue >= 0.05:\n",
    "            pass\n",
    "        \n",
    "    L = None\n",
    "    L = sorted(coef_dict.items(), key=lambda item:item[1], reverse=True)\n",
    "    select_feat = []\n",
    "    L = L[:num]#取出前幾個相關係數最大的\n",
    "    for ind in range(0, len(L)):\n",
    "        select_feat.append(L[ind][0])\n",
    "#     print(select_feat)\n",
    "#     X_train_new = X_train[select_feat]\n",
    "    joblib.dump(select_feat, f'try2/feat_columns_stacking1.pkl')\n",
    "\n",
    "find_cc_feat(X, y, num=85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feat = joblib.load(f'try2/feat_columns_stacking1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[select_feat]\n",
    "X_test = X_test[select_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE_TYPE6</th>\n",
       "      <th>TYPE_TYPE1</th>\n",
       "      <th>5-3_M_M30</th>\n",
       "      <th>5-3_M_M8</th>\n",
       "      <th>5-1_M_M22</th>\n",
       "      <th>5-2_M_M22</th>\n",
       "      <th>5-1_value</th>\n",
       "      <th>5-3_value</th>\n",
       "      <th>5-2_value</th>\n",
       "      <th>4-1_M_M7</th>\n",
       "      <th>...</th>\n",
       "      <th>5-1_M_M9</th>\n",
       "      <th>5-2_M_M9</th>\n",
       "      <th>TYPE_TYPE3</th>\n",
       "      <th>1-2_value</th>\n",
       "      <th>3-1_M_M15</th>\n",
       "      <th>5-3_M_M27</th>\n",
       "      <th>3-3_cell</th>\n",
       "      <th>6-1_M_M23</th>\n",
       "      <th>6-1_M_M9</th>\n",
       "      <th>2-3_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.599650</td>\n",
       "      <td>-0.593506</td>\n",
       "      <td>-0.884550</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.299932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.206358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.610767</td>\n",
       "      <td>-0.595598</td>\n",
       "      <td>-0.884550</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.618820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.080025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.506264</td>\n",
       "      <td>-0.587231</td>\n",
       "      <td>-0.684281</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.199665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486253</td>\n",
       "      <td>-0.587231</td>\n",
       "      <td>-0.619134</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.536096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.208032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.670800</td>\n",
       "      <td>-0.616516</td>\n",
       "      <td>-0.886962</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.562781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.189625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.154657</td>\n",
       "      <td>0.249479</td>\n",
       "      <td>1.144673</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.132909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.070165</td>\n",
       "      <td>0.195093</td>\n",
       "      <td>0.939580</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.131236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999015</td>\n",
       "      <td>0.193001</td>\n",
       "      <td>0.932341</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.127053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956769</td>\n",
       "      <td>0.195093</td>\n",
       "      <td>0.932341</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.119081</td>\n",
       "      <td>0.239020</td>\n",
       "      <td>1.139848</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.149642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5723 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TYPE_TYPE6  TYPE_TYPE1  5-3_M_M30  5-3_M_M8  5-1_M_M22  5-2_M_M22  \\\n",
       "0              1           0          0         1          0          0   \n",
       "1              1           0          0         1          0          0   \n",
       "2              1           0          0         1          0          0   \n",
       "3              1           0          0         1          0          0   \n",
       "4              1           0          0         1          0          0   \n",
       "...          ...         ...        ...       ...        ...        ...   \n",
       "5718           0           1          1         0          1          1   \n",
       "5719           0           1          1         0          1          1   \n",
       "5720           0           1          1         0          1          1   \n",
       "5721           0           1          1         0          1          1   \n",
       "5722           0           1          1         0          1          1   \n",
       "\n",
       "      5-1_value  5-3_value  5-2_value  4-1_M_M7  ...  5-1_M_M9  5-2_M_M9  \\\n",
       "0     -0.599650  -0.593506  -0.884550         0  ...         0         0   \n",
       "1     -0.610767  -0.595598  -0.884550         0  ...         0         0   \n",
       "2     -0.506264  -0.587231  -0.684281         0  ...         0         0   \n",
       "3     -0.486253  -0.587231  -0.619134         0  ...         0         0   \n",
       "4     -0.670800  -0.616516  -0.886962         0  ...         0         0   \n",
       "...         ...        ...        ...       ...  ...       ...       ...   \n",
       "5718   1.154657   0.249479   1.144673         0  ...         0         0   \n",
       "5719   1.070165   0.195093   0.939580         0  ...         0         0   \n",
       "5720   0.999015   0.193001   0.932341         0  ...         0         0   \n",
       "5721   0.956769   0.195093   0.932341         0  ...         0         0   \n",
       "5722   1.119081   0.239020   1.139848         0  ...         0         0   \n",
       "\n",
       "      TYPE_TYPE3  1-2_value  3-1_M_M15  5-3_M_M27  3-3_cell  6-1_M_M23  \\\n",
       "0              0  -0.299932          0          0 -0.733466          0   \n",
       "1              0  -0.618820          0          0 -0.733466          0   \n",
       "2              0  -0.253233          0          0 -0.733466          0   \n",
       "3              0  -0.536096          0          0 -0.733466          0   \n",
       "4              0  -0.562781          0          0 -0.733466          0   \n",
       "...          ...        ...        ...        ...       ...        ...   \n",
       "5718           0  -0.059098          0          0 -0.733466          0   \n",
       "5719           0  -0.059098          0          0 -0.733466          0   \n",
       "5720           0  -0.059098          0          0 -0.733466          0   \n",
       "5721           0  -0.059098          0          0 -0.733466          0   \n",
       "5722           0  -0.059098          0          0 -0.733466          0   \n",
       "\n",
       "      6-1_M_M9  2-3_value  \n",
       "0            1  -0.206358  \n",
       "1            1  -0.080025  \n",
       "2            1  -0.199665  \n",
       "3            1  -0.208032  \n",
       "4            1  -0.189625  \n",
       "...        ...        ...  \n",
       "5718         1   2.132909  \n",
       "5719         1   2.131236  \n",
       "5720         1   2.127053  \n",
       "5721         1   2.126216  \n",
       "5722         1   2.149642  \n",
       "\n",
       "[5723 rows x 84 columns]"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.575426388888889\n",
      "0.5691010638297872\n",
      "4.826889772727274\n",
      "1.6249874999999998\n"
     ]
    }
   ],
   "source": [
    "print(max(y['CIEX']))\n",
    "print(min(y['CIEX']))\n",
    "print(max(y['CIEY']))\n",
    "print(min(y['CIEY']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict CIEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#      X, y, test_size = 0.1, random_state=9\n",
    "#  )\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "     X, y, test_size = 0.1, random_state=14\n",
    " )\n",
    "y_train1 = y_train['CIEX']\n",
    "y_val1 = y_val['CIEX']\n",
    "\n",
    "# y_train2 = y_train['CIEY']\n",
    "# y_val2 = y_val['CIEY']\n",
    "\n",
    "# y_train3 = y_train['CIEX_DIFF']\n",
    "# y_val3 = y_val['CIEX_DIFF']\n",
    "\n",
    "# y_train4 = y_train['CIEY_DIFF']\n",
    "# y_val4 = y_val['CIEY_DIFF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig , ax = plt.subplots(figsize=(15, 20))\n",
    "# fig.subplots_adjust(hspace=0.5, wspace=0.3) #設定子圖的間隔\n",
    "\n",
    "# plt.subplot(1, 3, 1).set_title('before transformation')\n",
    "# plt.boxplot(y_train1)\n",
    "\n",
    "# plt.subplot(1, 3, 2).set_title('after transformation')\n",
    "# y_train1_new = trans(y_train1)\n",
    "# print(y_train1_new.shape)\n",
    "# plt.boxplot(y_train1_new)\n",
    "\n",
    "# plt.subplot(1, 3, 3).set_title('inv transformation')\n",
    "# y_train1_try = trans_inv(y_train1_new)\n",
    "# print(y_train1_try.shape)\n",
    "# plt.boxplot(y_train1_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators1 = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=50, max_depth=8, min_samples_split=2)),\n",
    "        ('svr',SVR(kernel='rbf', C=0.001, gamma=0.1, epsilon=.001)),\n",
    "        ('rid',Ridge(alpha=0.001,\n",
    "             solver = 'sparse_cg',\n",
    "             max_iter = 1200,\n",
    "             tol = 1e-7)),\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=7, \n",
    "                                    algorithm='auto', \n",
    "                                    leaf_size=100, \n",
    "                                    p=1,  \n",
    "                                    n_jobs=-1, )),\n",
    "        ('NBG', BayesianRidge(n_iter=500, \n",
    "                              tol=0.00001, \n",
    "                              alpha_1=1e-06, \n",
    "                              alpha_2=1e-06, \n",
    "                              lambda_1=1e-06, \n",
    "                              lambda_2=1e-06, \n",
    "                              compute_score=False,)),\n",
    "        ('PAR',PassiveAggressiveRegressor(C=170, \n",
    "                                      max_iter=1000, \n",
    "                                      tol=0.000001, \n",
    "                                      early_stopping=True,  \n",
    "                                      shuffle=True,  \n",
    "                                      loss='squared_epsilon_insensitive', \n",
    "                                      epsilon=0.0001, \n",
    "                                      random_state=None)),\n",
    "#         ('knn2', KNeighborsRegressor(n_neighbors=5, \n",
    "#                                     algorithm='auto', \n",
    "#                                     leaf_size=50, \n",
    "#                                     p=1,  \n",
    "#                                     n_jobs=-1, )),\n",
    "#         ('knn3', KNeighborsRegressor(n_neighbors=10, \n",
    "#                                     algorithm='auto', \n",
    "#                                     leaf_size=50, \n",
    "#                                     p=1,  \n",
    "#                                     n_jobs=-1, )),\n",
    "#           ('nn', nn(hidden_layer_sizes=(120, ), \n",
    "#                      activation='logistic',\n",
    "#                      solver='adam', \n",
    "#                      alpha=0.0001, \n",
    "#                      learning_rate_init=0.01, \n",
    "#                      power_t=0.5, \n",
    "#                      max_iter=200, \n",
    "#                      shuffle=True, \n",
    "#                      random_state=None, \n",
    "#                      tol=0.000001, \n",
    "#                      early_stopping=True, \n",
    "#                      validation_fraction=0.1, \n",
    "#                      epsilon=1e-08, )),\n",
    "    \n",
    "    \n",
    "        ]\n",
    "\n",
    "pred1 = np.zeros([4962, 1])\n",
    "for i in range(1):\n",
    "    model1 = StackingRegressor(\n",
    "     estimators=estimators1,\n",
    "            final_estimator=RandomForestRegressor(n_estimators=500, max_depth=7, min_samples_split=2))\n",
    "\n",
    "    model1.fit(X_train, y_train1)\n",
    "#     model1.fit(X, y['CIEX'])\n",
    "\n",
    "    pr_tr = model1.predict(X).reshape(-1,1)\n",
    "    pr_tr_1 = model1.predict(X_test).reshape(-1,1)\n",
    "#     pr_va = model1.predict(X_val)\n",
    "\n",
    "#     print(sum(np.abs(pr_tr - y_train1))/pr_tr.shape[0])\n",
    "#     l1 = sum(np.abs(pr_va - y_val1))/pr_va.shape[0]\n",
    "#     print(l1)\n",
    "    pred1 += pr_tr\n",
    "pred1 /= 1\n",
    "\n",
    "# joblib.dump(model1, f'try2/CIEX.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012285279459003098\n"
     ]
    }
   ],
   "source": [
    "# print(sum(np.abs(pred1.reshape(-1) - y['CIEX']))/pred1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['try2/CIEX.pkl']"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(model1, f'try2/CIEX.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.13885893],\n",
       "       [3.1388572 ],\n",
       "       [3.13648877],\n",
       "       ...,\n",
       "       [0.7320302 ],\n",
       "       [0.7320282 ],\n",
       "       [0.73202469]])"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict CIEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIEX</th>\n",
       "      <th>CIEY</th>\n",
       "      <th>CIEX_DIFF</th>\n",
       "      <th>CIEY_DIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.138889</td>\n",
       "      <td>2.161998</td>\n",
       "      <td>0.00310</td>\n",
       "      <td>0.00310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.139217</td>\n",
       "      <td>2.162539</td>\n",
       "      <td>0.00355</td>\n",
       "      <td>0.00250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.139260</td>\n",
       "      <td>2.161272</td>\n",
       "      <td>0.00660</td>\n",
       "      <td>0.00460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.133462</td>\n",
       "      <td>2.159586</td>\n",
       "      <td>0.00445</td>\n",
       "      <td>0.00220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134885</td>\n",
       "      <td>2.160474</td>\n",
       "      <td>0.00475</td>\n",
       "      <td>0.00220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>0.733000</td>\n",
       "      <td>4.750889</td>\n",
       "      <td>0.00320</td>\n",
       "      <td>0.00265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>0.732655</td>\n",
       "      <td>4.751256</td>\n",
       "      <td>0.00270</td>\n",
       "      <td>0.00275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>0.732672</td>\n",
       "      <td>4.751435</td>\n",
       "      <td>0.00285</td>\n",
       "      <td>0.00265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>0.732709</td>\n",
       "      <td>4.751304</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.00255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>0.732784</td>\n",
       "      <td>4.751198</td>\n",
       "      <td>0.00270</td>\n",
       "      <td>0.00335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4962 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CIEX      CIEY  CIEX_DIFF  CIEY_DIFF\n",
       "0     3.138889  2.161998    0.00310    0.00310\n",
       "1     3.139217  2.162539    0.00355    0.00250\n",
       "2     3.139260  2.161272    0.00660    0.00460\n",
       "3     3.133462  2.159586    0.00445    0.00220\n",
       "4     3.134885  2.160474    0.00475    0.00220\n",
       "...        ...       ...        ...        ...\n",
       "4957  0.733000  4.750889    0.00320    0.00265\n",
       "4958  0.732655  4.751256    0.00270    0.00275\n",
       "4959  0.732672  4.751435    0.00285    0.00265\n",
       "4960  0.732709  4.751304    0.00295    0.00255\n",
       "4961  0.732784  4.751198    0.00270    0.00335\n",
       "\n",
       "[4962 rows x 4 columns]"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "     X, y, test_size = 0.1, random_state=12\n",
    " )\n",
    "# y_train1 = y_train['CIEX']\n",
    "# y_val1 = y_val['CIEX']\n",
    "\n",
    "y_train2 = y_train['CIEY']\n",
    "y_val2 = y_val['CIEY']\n",
    "\n",
    "# y_train3 = y_train['CIEX_DIFF']\n",
    "# y_val3 = y_val['CIEX_DIFF']\n",
    "\n",
    "# y_train4 = y_train['CIEY_DIFF']\n",
    "# y_val4 = y_val['CIEY_DIFF']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators2 = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=50, max_depth=8, min_samples_split=2)),\n",
    "        ('svr',SVR(kernel='rbf', C=0.01, gamma=0.1, epsilon=.001)),\n",
    "        ('rid',Ridge(alpha=0.001,\n",
    "             solver = 'sparse_cg',\n",
    "             max_iter = 1200,\n",
    "             tol = 1e-7)),\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=7, \n",
    "                                    algorithm='auto', \n",
    "                                    leaf_size=100, \n",
    "                                    p=1,  \n",
    "                                    n_jobs=-1, )),\n",
    "        ('NBG', BayesianRidge(n_iter=500, \n",
    "                              tol=0.00001, \n",
    "                              alpha_1=1e-06, \n",
    "                              alpha_2=1e-06, \n",
    "                              lambda_1=1e-06, \n",
    "                              lambda_2=1e-06, \n",
    "                              compute_score=False,)),\n",
    "#     ('PAR',PassiveAggressiveRegressor(C=10, \n",
    "#                                       max_iter=1000, \n",
    "#                                       tol=0.000001, \n",
    "#                                       early_stopping=True,  \n",
    "#                                       shuffle=True,  \n",
    "#                                       loss='squared_epsilon_insensitive', \n",
    "#                                       epsilon=0.001, \n",
    "#                                       random_state=None)),\n",
    "    \n",
    "        ]\n",
    "\n",
    "pred2 = np.zeros([4962, 1])\n",
    "for i in range(1):\n",
    "    model2 = StackingRegressor(\n",
    "     estimators=estimators2,\n",
    "            final_estimator=RandomForestRegressor(n_estimators=100, max_depth=8, min_samples_split=2))\n",
    "\n",
    "    model2.fit(X_train, y_train2)\n",
    "#     model2.fit(X, y['CIEY'])\n",
    "\n",
    "    pr_tr = model2.predict(X).reshape(-1, 1)\n",
    "    pr_tr_2 = model2.predict(X_test).reshape(-1,1)\n",
    "#     pr_va = model2.predict(X_val)\n",
    "\n",
    "#     print(sum(np.abs(pr_tr - y_train2))/pr_tr.shape[0])\n",
    "#     l2 = sum(np.abs(pr_va - y_val2))/pr_va.shape[0]\n",
    "#     print(l2)\n",
    "\n",
    "#     print(pr_tr[0, 0])\n",
    "    pred2 = pred2 + pr_tr\n",
    "    \n",
    "pred2 /= 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['try2/CIEY.pkl']"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(model2, f'try2/CIEY.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict CIEX_DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "     X, y, test_size = 0.1, random_state=12\n",
    "    #9\n",
    " )\n",
    "y_train3 = y_train['CIEX_DIFF']\n",
    "y_val3 = y_val['CIEX_DIFF']\n",
    "\n",
    "y_train3_new = trans(y_train3)\n",
    "y_val3_new = trans(y_val3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trans(y_):\n",
    "    \n",
    "    y = (y_ + 4.01)/4\n",
    "    y = boxcox(y, -1000)\n",
    "    return y\n",
    "\n",
    "def trans_inv(y):\n",
    "    y_ = inv_boxcox(y, -1000)\n",
    "    y_ = y_ * 4 - 4.01 \n",
    "    return y_\n",
    "\n",
    "# def trans(y_):\n",
    "#     y = y_ + 1\n",
    "#     y = np.log(y)\n",
    "#     return y\n",
    "\n",
    "# def trans_inv(y):\n",
    "#     y_ = np.exp(y)\n",
    "#     y_ = y_ - 1 \n",
    "#     return y_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# fig , ax = plt.subplots(figsize=(15, 20))\n",
    "# fig.subplots_adjust(hspace=0.5, wspace=0.3) #設定子圖的間隔\n",
    "\n",
    "# plt.subplot(1, 3, 1).set_title('before transformation')\n",
    "# plt.boxplot(y_train3)\n",
    "\n",
    "# plt.subplot(1, 3, 2).set_title('after transformation')\n",
    "# y_train3_new = trans(y_train3)\n",
    "# print(y_train3_new.shape)\n",
    "# plt.boxplot(y_train3_new)\n",
    "\n",
    "# plt.subplot(1, 3, 3).set_title('inv transformation')\n",
    "# y_train3_try = trans_inv(y_train3_new)\n",
    "# print(y_train3_try.shape)\n",
    "# plt.boxplot(y_train3_try)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train3 = np.log(y_train3)\n",
    "\n",
    "\n",
    "estimators3 = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=50, max_depth=6, min_samples_split=2)),\n",
    "        ('lib',LinearRegression()),\n",
    "#         ('svr',SVR(kernel='rbf', C=0.001, gamma=0.1, epsilon=.001)),\n",
    "        ('rid',Ridge(alpha=0.001,\n",
    "             solver = 'sparse_cg',\n",
    "             max_iter = 1200,\n",
    "             tol = 1e-7),),\n",
    "        ('knn1', KNeighborsRegressor(n_neighbors=7, \n",
    "                                    algorithm='auto', \n",
    "                                    leaf_size=50, \n",
    "                                    p=1,  \n",
    "                                    n_jobs=-1, )),\n",
    "        ('NBG', BayesianRidge(n_iter=500, \n",
    "                              tol=0.00001, \n",
    "                              alpha_1=1e-06, \n",
    "                              alpha_2=1e-06, \n",
    "                              lambda_1=1e-06, \n",
    "                              lambda_2=1e-06, \n",
    "                              compute_score=False,)),\n",
    "        ('knn2', KNeighborsRegressor(n_neighbors=5, \n",
    "                                    algorithm='auto', \n",
    "                                    leaf_size=50, \n",
    "                                    p=1,  \n",
    "                                    n_jobs=-1, )),\n",
    "        ('knn3', KNeighborsRegressor(n_neighbors=10, \n",
    "                                    algorithm='auto', \n",
    "                                    leaf_size=50, \n",
    "                                    p=1,  \n",
    "                                    n_jobs=-1, )),\n",
    "        ('PAR',PassiveAggressiveRegressor(C=100, \n",
    "                                      max_iter=1200, \n",
    "                                      tol=0.000001, \n",
    "                                      early_stopping=True,  \n",
    "                                      shuffle=True,  \n",
    "                                      loss='squared_epsilon_insensitive', \n",
    "                                      epsilon=0.0001, \n",
    "                                      random_state=None)),\n",
    "        ]\n",
    "\n",
    "pred3 = np.zeros([4962, 1])\n",
    "for i in range(1):\n",
    "    model3 = StackingRegressor(\n",
    "                         estimators=estimators3,\n",
    "                                final_estimator=RandomForestRegressor(n_estimators=500, max_depth=8, min_samples_split=2))\n",
    "\n",
    "    # model3.fit(X_train, y_train3)\n",
    "    model3.fit(X_train, y_train3_new)\n",
    "#     model3.fit(X, trans(y['CIEX_DIFF']))\n",
    "\n",
    "    pr_tr = trans_inv(model3.predict(X)).reshape(-1,1)#還沒變回來！\n",
    "    pr_tr_3 = trans_inv(model3.predict(X_test)).reshape(-1,1)\n",
    "#     pr_va = model3.predict(X_val)#還沒變回來！\n",
    "\n",
    "#     print('true predict')\n",
    "#     print(sum(np.abs(trans_inv(pr_tr) - y_train3))/y_train3.shape[0])\n",
    "#     l3 = sum(np.abs(trans_inv(pr_va) - y_val3))/y_val3.shape[0]\n",
    "#     print(l3)\n",
    "\n",
    "#     print()\n",
    "#     print('predict after trans')\n",
    "#     print(sum(np.abs(pr_tr - y_train3_new))/y_train3_new.shape[0])\n",
    "#     l3 = sum(np.abs(pr_va - y_val3_new))/y_val3_new.shape[0]\n",
    "#     print(l3)\n",
    "\n",
    "# joblib.dump(model3, f'try2/CIEX_DIFF.pkl')\n",
    "    pred3 += pr_tr\n",
    "    \n",
    "pred3 = pred3/1\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# # plt.axis([0, 0.2, 0, 0.2])\n",
    "# plt.plot(pr_tr, y_train3_new, 'b.')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['try2/CIEX_DIFF.pkl']"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(model3, f'try2/CIEX_DIFF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00507616],\n",
       "       [0.00505346],\n",
       "       [0.00512484],\n",
       "       ...,\n",
       "       [0.0031411 ],\n",
       "       [0.00300534],\n",
       "       [0.00293169]])"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_tr_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict CIEY_DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIEX</th>\n",
       "      <th>CIEY</th>\n",
       "      <th>CIEX_DIFF</th>\n",
       "      <th>CIEY_DIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.138889</td>\n",
       "      <td>2.161998</td>\n",
       "      <td>0.00310</td>\n",
       "      <td>0.00310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.139217</td>\n",
       "      <td>2.162539</td>\n",
       "      <td>0.00355</td>\n",
       "      <td>0.00250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.139260</td>\n",
       "      <td>2.161272</td>\n",
       "      <td>0.00660</td>\n",
       "      <td>0.00460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.133462</td>\n",
       "      <td>2.159586</td>\n",
       "      <td>0.00445</td>\n",
       "      <td>0.00220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134885</td>\n",
       "      <td>2.160474</td>\n",
       "      <td>0.00475</td>\n",
       "      <td>0.00220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>0.733000</td>\n",
       "      <td>4.750889</td>\n",
       "      <td>0.00320</td>\n",
       "      <td>0.00265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>0.732655</td>\n",
       "      <td>4.751256</td>\n",
       "      <td>0.00270</td>\n",
       "      <td>0.00275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>0.732672</td>\n",
       "      <td>4.751435</td>\n",
       "      <td>0.00285</td>\n",
       "      <td>0.00265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>0.732709</td>\n",
       "      <td>4.751304</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.00255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>0.732784</td>\n",
       "      <td>4.751198</td>\n",
       "      <td>0.00270</td>\n",
       "      <td>0.00335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4962 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CIEX      CIEY  CIEX_DIFF  CIEY_DIFF\n",
       "0     3.138889  2.161998    0.00310    0.00310\n",
       "1     3.139217  2.162539    0.00355    0.00250\n",
       "2     3.139260  2.161272    0.00660    0.00460\n",
       "3     3.133462  2.159586    0.00445    0.00220\n",
       "4     3.134885  2.160474    0.00475    0.00220\n",
       "...        ...       ...        ...        ...\n",
       "4957  0.733000  4.750889    0.00320    0.00265\n",
       "4958  0.732655  4.751256    0.00270    0.00275\n",
       "4959  0.732672  4.751435    0.00285    0.00265\n",
       "4960  0.732709  4.751304    0.00295    0.00255\n",
       "4961  0.732784  4.751198    0.00270    0.00335\n",
       "\n",
       "[4962 rows x 4 columns]"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "     X, y, test_size = 0.1, random_state=14\n",
    " )\n",
    "# y_train1 = y_train['CIEX']\n",
    "# y_val1 = y_val['CIEX']\n",
    "\n",
    "# y_train2 = y_train['CIEY']\n",
    "# y_val2 = y_val['CIEY']\n",
    "\n",
    "# y_train3 = y_train['CIEX_DIFF']\n",
    "# y_val3 = y_val['CIEX_DIFF']\n",
    "\n",
    "y_train4 = y_train['CIEY_DIFF']\n",
    "y_val4 = y_val['CIEY_DIFF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x14aa15d90>,\n",
       "  <matplotlib.lines.Line2D at 0x14aa18310>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x14aa18850>,\n",
       "  <matplotlib.lines.Line2D at 0x14aa18d90>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x14aa15850>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x14afd8350>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x14afd8890>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train4_new = trans(y_train4)\n",
    "y_val4_new = trans(y_val4)\n",
    "\n",
    "fig , ax = plt.subplots(figsize=(10, 10))\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.3) #設定子圖的間隔\n",
    "\n",
    "plt.subplot(1, 2, 1).set_title('before transformation')\n",
    "plt.boxplot(y_train4)\n",
    "\n",
    "plt.subplot(1, 2, 2).set_title('after transformation')\n",
    "plt.boxplot(y_train4_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train4 = np.log(y_train4)\n",
    "estimators4 = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=50, max_depth=6, min_samples_split=2)),\n",
    "        ('svr',SVR(kernel='rbf', C=0.01, gamma=0.1, epsilon=.001)),\n",
    "        ('rid',Ridge(alpha=0.001,\n",
    "             solver = 'sparse_cg',\n",
    "             max_iter = 1200,\n",
    "             tol = 1e-7)),\n",
    "        ('knn1', KNeighborsRegressor(n_neighbors=7, \n",
    "                                    algorithm='auto', \n",
    "                                    leaf_size=50, \n",
    "                                    p=1,  \n",
    "                                    n_jobs=-1, )),\n",
    "        ('NBG', BayesianRidge(n_iter=500, \n",
    "                              tol=0.00001, \n",
    "                              alpha_1=1e-06, \n",
    "                              alpha_2=1e-06, \n",
    "                              lambda_1=1e-06, \n",
    "                              lambda_2=1e-06, \n",
    "                              compute_score=False,)),\n",
    "        ('knn2', KNeighborsRegressor(n_neighbors=5, \n",
    "                                    algorithm='auto', \n",
    "                                    leaf_size=50, \n",
    "                                    p=1,  \n",
    "                                    n_jobs=-1, )),\n",
    "        ('knn3', KNeighborsRegressor(n_neighbors=10, \n",
    "                                    algorithm='auto', \n",
    "                                    leaf_size=50, \n",
    "                                    p=1,  \n",
    "                                    n_jobs=-1, )),\n",
    "#         ('PAR',PassiveAggressiveRegressor(C=100, \n",
    "#                                       max_iter=1200, \n",
    "#                                       tol=0.000001, \n",
    "#                                       early_stopping=True,  \n",
    "#                                       shuffle=True,  \n",
    "#                                       loss='squared_epsilon_insensitive', \n",
    "#                                       epsilon=0.001, \n",
    "#                                       random_state=None)),\n",
    "    \n",
    "        ]\n",
    "pred4 = np.zeros([4962, 1])\n",
    "for i in range(1):\n",
    "    model4 = StackingRegressor(\n",
    "     estimators=estimators4,\n",
    "        final_estimator=RandomForestRegressor(n_estimators=300, max_depth=6, min_samples_split=2))\n",
    "\n",
    "    model4.fit(X_train, y_train4_new)\n",
    "#     model4.fit(X, trans(y['CIEY_DIFF']))\n",
    "\n",
    "    pr_tr = trans_inv(model4.predict(X)).reshape(-1, 1)#log type\n",
    "    pr_tr_4 = trans_inv(model4.predict(X_test)).reshape(-1, 1)\n",
    "#     pr_va = model4.predict(X_val)#log type\n",
    "\n",
    "#     print('true predict')\n",
    "#     print(sum(np.abs(trans_inv(pr_tr) - y_train4))/y_train4.shape[0])\n",
    "#     l4 = sum(np.abs(trans_inv(pr_va) - y_val4))/y_val4.shape[0]\n",
    "#     print(l4)\n",
    "\n",
    "#     print()\n",
    "#     print('predict after trans')\n",
    "#     print(sum(np.abs(pr_tr - y_train4_new))/y_train4_new.shape[0])\n",
    "#     l4 = sum(np.abs(pr_va - y_val4_new))/y_val4_new.shape[0]\n",
    "#     print(l4)\n",
    "    pred4 += pr_tr\n",
    "pred4 /= 1\n",
    "\n",
    "# joblib.dump(model4, f'try2/CIEY_DIFF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jjijijjjjjjjjjjjijijijijijijiji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001057131417800198\n",
      "0.001096093093151119\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "     pred1, y, test_size = 0.1, random_state=17\n",
    " )\n",
    "\n",
    "y_train1 = y_train['CIEX']\n",
    "y_val1 = y_val['CIEX']\n",
    "\n",
    "# y_train2 = y_train['CIEY']\n",
    "# y_val2 = y_val['CIEY']\n",
    "\n",
    "# y_train3 = y_train['CIEX_DIFF']\n",
    "# y_val3 = y_val['CIEX_DIFF']\n",
    "\n",
    "# y_train4 = y_train['CIEY_DIFF']\n",
    "# y_val4 = y_val['CIEY_DIFF']\n",
    "\n",
    "model1 = RandomForestRegressor(n_estimators=6, max_depth=8, min_samples_split=2)\n",
    "\n",
    "model1.fit(X_train, y_train1)\n",
    "\n",
    "a = model1.predict(X_train)\n",
    "b = model1.predict(X_val)\n",
    "print(sum(np.abs(a - y_train1))/y_train1.shape[0])\n",
    "print(sum(np.abs(b - y_val1))/y_val1.shape[0])\n",
    "\n",
    "pr_tr_1_ = model1.predict(pr_tr_1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008417768852936154\n",
      "0.0008168444175046219\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "     pred2, y, test_size = 0.1, random_state=2\n",
    " )\n",
    "\n",
    "y_train2 = y_train['CIEY']\n",
    "y_val2 = y_val['CIEY']\n",
    "\n",
    "# y_train2 = y_train['CIEY']\n",
    "# y_val2 = y_val['CIEY']\n",
    "\n",
    "# y_train3 = y_train['CIEX_DIFF']\n",
    "# y_val3 = y_val['CIEX_DIFF']\n",
    "\n",
    "# y_train4 = y_train['CIEY_DIFF']\n",
    "# y_val4 = y_val['CIEY_DIFF']\n",
    "\n",
    "model2 = RandomForestRegressor(n_estimators=6, max_depth=7, min_samples_split=2)\n",
    "\n",
    "model2.fit(X_train, y_train2)\n",
    "\n",
    "a = model2.predict(X_train)\n",
    "b = model2.predict(X_val)\n",
    "print(sum(np.abs(a - y_train2))/y_train2.shape[0])\n",
    "print(sum(np.abs(b - y_val2))/y_val2.shape[0])\n",
    "\n",
    "pr_tr_2_ = model2.predict(pr_tr_2).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.15991858],\n",
       "       [2.15947084],\n",
       "       [2.15947084],\n",
       "       ...,\n",
       "       [4.75137642],\n",
       "       [4.75132428],\n",
       "       [4.75132428]])"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_tr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019906117137149047\n",
      "0.001539112893716264\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "     pred3, y, test_size = 0.2, random_state=6\n",
    " )\n",
    "\n",
    "y_train3 = y_train['CIEX_DIFF']\n",
    "y_val3 = y_val['CIEX_DIFF']\n",
    "\n",
    "# y_train2 = y_train['CIEY']\n",
    "# y_val2 = y_val['CIEY']\n",
    "\n",
    "# y_train3 = y_train['CIEX_DIFF']\n",
    "# y_val3 = y_val['CIEX_DIFF']\n",
    "\n",
    "# y_train4 = y_train['CIEY_DIFF']\n",
    "# y_val4 = y_val['CIEY_DIFF']\n",
    "\n",
    "model3 = RandomForestRegressor(n_estimators=6, max_depth=6, min_samples_split=2)\n",
    "\n",
    "model3.fit(X_train, trans(y_train3))\n",
    "\n",
    "a = trans_inv(model3.predict(X_train))\n",
    "b = trans_inv(model3.predict(X_val))\n",
    "print(sum(np.abs(a - y_train3))/y_train3.shape[0])\n",
    "print(sum(np.abs(b - y_val3))/y_val3.shape[0])\n",
    "\n",
    "pr_tr_3_ = trans_inv(model3.predict(pr_tr_3)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00192696]\n"
     ]
    }
   ],
   "source": [
    "# print(sum(np.abs(pred3.reshape(-1, 1) - y['CIEX_DIFF'].to_numpy().reshape(-1, 1)))/pred3.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015550221518158915\n",
      "0.0011771497618804185\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "     pred4, y, test_size = 0.2, random_state=2\n",
    " )\n",
    "\n",
    "y_train4 = y_train['CIEY_DIFF']\n",
    "y_val4 = y_val['CIEY_DIFF']\n",
    "\n",
    "# y_train2 = y_train['CIEY']\n",
    "# y_val2 = y_val['CIEY']\n",
    "\n",
    "# y_train3 = y_train['CIEX_DIFF']\n",
    "# y_val3 = y_val['CIEX_DIFF']\n",
    "\n",
    "# y_train4 = y_train['CIEY_DIFF']\n",
    "# y_val4 = y_val['CIEY_DIFF']\n",
    "\n",
    "model4 = RandomForestRegressor(n_estimators=6, max_depth=8, min_samples_split=2)\n",
    "\n",
    "model4.fit(X_train, trans(y_train4))\n",
    "\n",
    "a = trans_inv(model4.predict(X_train))\n",
    "b = trans_inv(model4.predict(X_val))\n",
    "print(sum(np.abs(a - y_train4))/y_train4.shape[0])\n",
    "print(sum(np.abs(b - y_val4))/y_val4.shape[0])\n",
    "\n",
    "pr_tr_4_ = trans_inv(model4.predict(pr_tr_4)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE_TYPE6</th>\n",
       "      <th>TYPE_TYPE1</th>\n",
       "      <th>5-3_M_M30</th>\n",
       "      <th>5-3_M_M8</th>\n",
       "      <th>5-1_M_M22</th>\n",
       "      <th>5-2_M_M22</th>\n",
       "      <th>5-1_value</th>\n",
       "      <th>5-3_value</th>\n",
       "      <th>5-2_value</th>\n",
       "      <th>4-1_M_M7</th>\n",
       "      <th>...</th>\n",
       "      <th>5-1_M_M9</th>\n",
       "      <th>5-2_M_M9</th>\n",
       "      <th>TYPE_TYPE3</th>\n",
       "      <th>1-2_value</th>\n",
       "      <th>3-1_M_M15</th>\n",
       "      <th>5-3_M_M27</th>\n",
       "      <th>3-3_cell</th>\n",
       "      <th>6-1_M_M23</th>\n",
       "      <th>6-1_M_M9</th>\n",
       "      <th>2-3_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.599650</td>\n",
       "      <td>-0.593506</td>\n",
       "      <td>-0.884550</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.299932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.206358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.610767</td>\n",
       "      <td>-0.595598</td>\n",
       "      <td>-0.884550</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.618820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.080025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.506264</td>\n",
       "      <td>-0.587231</td>\n",
       "      <td>-0.684281</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.199665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486253</td>\n",
       "      <td>-0.587231</td>\n",
       "      <td>-0.619134</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.536096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.208032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.670800</td>\n",
       "      <td>-0.616516</td>\n",
       "      <td>-0.886962</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.562781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.189625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.154657</td>\n",
       "      <td>0.249479</td>\n",
       "      <td>1.144673</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.132909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.070165</td>\n",
       "      <td>0.195093</td>\n",
       "      <td>0.939580</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.131236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999015</td>\n",
       "      <td>0.193001</td>\n",
       "      <td>0.932341</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.127053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956769</td>\n",
       "      <td>0.195093</td>\n",
       "      <td>0.932341</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.119081</td>\n",
       "      <td>0.239020</td>\n",
       "      <td>1.139848</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.733466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.149642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5723 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TYPE_TYPE6  TYPE_TYPE1  5-3_M_M30  5-3_M_M8  5-1_M_M22  5-2_M_M22  \\\n",
       "0              1           0          0         1          0          0   \n",
       "1              1           0          0         1          0          0   \n",
       "2              1           0          0         1          0          0   \n",
       "3              1           0          0         1          0          0   \n",
       "4              1           0          0         1          0          0   \n",
       "...          ...         ...        ...       ...        ...        ...   \n",
       "5718           0           1          1         0          1          1   \n",
       "5719           0           1          1         0          1          1   \n",
       "5720           0           1          1         0          1          1   \n",
       "5721           0           1          1         0          1          1   \n",
       "5722           0           1          1         0          1          1   \n",
       "\n",
       "      5-1_value  5-3_value  5-2_value  4-1_M_M7  ...  5-1_M_M9  5-2_M_M9  \\\n",
       "0     -0.599650  -0.593506  -0.884550         0  ...         0         0   \n",
       "1     -0.610767  -0.595598  -0.884550         0  ...         0         0   \n",
       "2     -0.506264  -0.587231  -0.684281         0  ...         0         0   \n",
       "3     -0.486253  -0.587231  -0.619134         0  ...         0         0   \n",
       "4     -0.670800  -0.616516  -0.886962         0  ...         0         0   \n",
       "...         ...        ...        ...       ...  ...       ...       ...   \n",
       "5718   1.154657   0.249479   1.144673         0  ...         0         0   \n",
       "5719   1.070165   0.195093   0.939580         0  ...         0         0   \n",
       "5720   0.999015   0.193001   0.932341         0  ...         0         0   \n",
       "5721   0.956769   0.195093   0.932341         0  ...         0         0   \n",
       "5722   1.119081   0.239020   1.139848         0  ...         0         0   \n",
       "\n",
       "      TYPE_TYPE3  1-2_value  3-1_M_M15  5-3_M_M27  3-3_cell  6-1_M_M23  \\\n",
       "0              0  -0.299932          0          0 -0.733466          0   \n",
       "1              0  -0.618820          0          0 -0.733466          0   \n",
       "2              0  -0.253233          0          0 -0.733466          0   \n",
       "3              0  -0.536096          0          0 -0.733466          0   \n",
       "4              0  -0.562781          0          0 -0.733466          0   \n",
       "...          ...        ...        ...        ...       ...        ...   \n",
       "5718           0  -0.059098          0          0 -0.733466          0   \n",
       "5719           0  -0.059098          0          0 -0.733466          0   \n",
       "5720           0  -0.059098          0          0 -0.733466          0   \n",
       "5721           0  -0.059098          0          0 -0.733466          0   \n",
       "5722           0  -0.059098          0          0 -0.733466          0   \n",
       "\n",
       "      6-1_M_M9  2-3_value  \n",
       "0            1  -0.206358  \n",
       "1            1  -0.080025  \n",
       "2            1  -0.199665  \n",
       "3            1  -0.208032  \n",
       "4            1  -0.189625  \n",
       "...        ...        ...  \n",
       "5718         1   2.132909  \n",
       "5719         1   2.131236  \n",
       "5720         1   2.127053  \n",
       "5721         1   2.126216  \n",
       "5722         1   2.149642  \n",
       "\n",
       "[5723 rows x 84 columns]"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = ['CIEX', 'CIEY', 'CIEX_DIFF', 'CIEY_DIFF']\n",
    "outcome = np.empty([5723, 0])\n",
    "for i in range(4):\n",
    "    model = joblib.load(f'try2/{label_name[i]}.pkl')\n",
    "    if i <= 1:\n",
    "        pred = model.predict(X_test).reshape(-1, 1)\n",
    "#         print(pred)\n",
    "        outcome = np.hstack((outcome, pred))\n",
    "    elif i>=2:\n",
    "#         print(pred)\n",
    "        pred = trans_inv(model.predict(X_test)).reshape(-1, 1)\n",
    "#         print(pred)\n",
    "        outcome = np.hstack((outcome, pred))\n",
    "#         print(outcome)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.13867829e+00, 2.16024949e+00, 4.96325081e-03, 3.58025907e-03],\n",
       "       [3.13713433e+00, 2.15936095e+00, 4.91641515e-03, 3.22997277e-03],\n",
       "       [3.13713433e+00, 2.15943773e+00, 4.98340406e-03, 3.55521965e-03],\n",
       "       ...,\n",
       "       [7.31970472e-01, 4.75148139e+00, 3.14793676e-03, 2.73135896e-03],\n",
       "       [7.31961963e-01, 4.75141624e+00, 3.06824336e-03, 2.75740538e-03],\n",
       "       [7.31956824e-01, 4.75140523e+00, 2.96896114e-03, 2.76299824e-03]])"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = pd.read_csv(\"data/sub2.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data0['CIEX'] = pred1\n",
    "# data0['CIEY'] = pred2\n",
    "# data0['CIEX_DIFF'] = pred3\n",
    "# data0['CIEY_DIFF'] = pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0['CIEX'] = pr_tr_1_\n",
    "data0['CIEY'] = pr_tr_2_\n",
    "data0['CIEX_DIFF'] = pr_tr_3_\n",
    "data0['CIEY_DIFF'] = pr_tr_4_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CIEX</th>\n",
       "      <th>CIEY</th>\n",
       "      <th>CIEX_DIFF</th>\n",
       "      <th>CIEY_DIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3.138436</td>\n",
       "      <td>3.130983</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.003371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3.137128</td>\n",
       "      <td>3.130983</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.003048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3.137128</td>\n",
       "      <td>3.130983</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.003389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3.138246</td>\n",
       "      <td>3.130983</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.003972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>3.138436</td>\n",
       "      <td>3.130983</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.003706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>10674</td>\n",
       "      <td>0.732028</td>\n",
       "      <td>1.625235</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>10675</td>\n",
       "      <td>0.732028</td>\n",
       "      <td>1.625235</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>10676</td>\n",
       "      <td>0.731980</td>\n",
       "      <td>1.625235</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.002731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>10680</td>\n",
       "      <td>0.731980</td>\n",
       "      <td>1.625235</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>10684</td>\n",
       "      <td>0.732028</td>\n",
       "      <td>1.625235</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5723 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      CIEX      CIEY  CIEX_DIFF  CIEY_DIFF\n",
       "0         2  3.138436  3.130983   0.005010   0.003371\n",
       "1         4  3.137128  3.130983   0.005010   0.003048\n",
       "2         5  3.137128  3.130983   0.005010   0.003389\n",
       "3         7  3.138246  3.130983   0.005010   0.003972\n",
       "4        10  3.138436  3.130983   0.005010   0.003706\n",
       "...     ...       ...       ...        ...        ...\n",
       "5718  10674  0.732028  1.625235   0.003064   0.002760\n",
       "5719  10675  0.732028  1.625235   0.002991   0.002812\n",
       "5720  10676  0.731980  1.625235   0.002991   0.002731\n",
       "5721  10680  0.731980  1.625235   0.002937   0.002760\n",
       "5722  10684  0.732028  1.625235   0.002909   0.002760\n",
       "\n",
       "[5723 rows x 5 columns]"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CIEX</th>\n",
       "      <th>CIEY</th>\n",
       "      <th>CIEX_DIFF</th>\n",
       "      <th>CIEY_DIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3.138436</td>\n",
       "      <td>3.130983</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.003371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3.137128</td>\n",
       "      <td>3.130983</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.003048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3.137128</td>\n",
       "      <td>3.130983</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.003389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3.138246</td>\n",
       "      <td>3.130983</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.003972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>3.138436</td>\n",
       "      <td>3.130983</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.003706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>10674</td>\n",
       "      <td>0.732028</td>\n",
       "      <td>1.625235</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>10675</td>\n",
       "      <td>0.732028</td>\n",
       "      <td>1.625235</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>10676</td>\n",
       "      <td>0.731980</td>\n",
       "      <td>1.625235</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.002731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>10680</td>\n",
       "      <td>0.731980</td>\n",
       "      <td>1.625235</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>10684</td>\n",
       "      <td>0.732028</td>\n",
       "      <td>1.625235</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5723 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      CIEX      CIEY  CIEX_DIFF  CIEY_DIFF\n",
       "0         2  3.138436  3.130983   0.005010   0.003371\n",
       "1         4  3.137128  3.130983   0.005010   0.003048\n",
       "2         5  3.137128  3.130983   0.005010   0.003389\n",
       "3         7  3.138246  3.130983   0.005010   0.003972\n",
       "4        10  3.138436  3.130983   0.005010   0.003706\n",
       "...     ...       ...       ...        ...        ...\n",
       "5718  10674  0.732028  1.625235   0.003064   0.002760\n",
       "5719  10675  0.732028  1.625235   0.002991   0.002812\n",
       "5720  10676  0.731980  1.625235   0.002991   0.002731\n",
       "5721  10680  0.731980  1.625235   0.002937   0.002760\n",
       "5722  10684  0.732028  1.625235   0.002909   0.002760\n",
       "\n",
       "[5723 rows x 5 columns]"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.to_csv(\"data/sub2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/submission.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CIEX</th>\n",
       "      <th>CIEY</th>\n",
       "      <th>CIEX_DIFF</th>\n",
       "      <th>CIEY_DIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3.138678</td>\n",
       "      <td>2.160230</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.003580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3.137134</td>\n",
       "      <td>2.159414</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.003230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3.137134</td>\n",
       "      <td>2.159569</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.003555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3.138528</td>\n",
       "      <td>2.159562</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.004036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>3.138702</td>\n",
       "      <td>2.159433</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.003644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>10674</td>\n",
       "      <td>0.731971</td>\n",
       "      <td>4.751474</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>10675</td>\n",
       "      <td>0.731972</td>\n",
       "      <td>4.751415</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>0.002744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>10676</td>\n",
       "      <td>0.731970</td>\n",
       "      <td>4.751394</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.002731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>10680</td>\n",
       "      <td>0.731962</td>\n",
       "      <td>4.751364</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>10684</td>\n",
       "      <td>0.731957</td>\n",
       "      <td>4.751355</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.002763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5723 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      CIEX      CIEY  CIEX_DIFF  CIEY_DIFF\n",
       "0         2  3.138678  2.160230   0.004966   0.003580\n",
       "1         4  3.137134  2.159414   0.004961   0.003230\n",
       "2         5  3.137134  2.159569   0.005001   0.003555\n",
       "3         7  3.138528  2.159562   0.004896   0.004036\n",
       "4        10  3.138702  2.159433   0.004991   0.003644\n",
       "...     ...       ...       ...        ...        ...\n",
       "5718  10674  0.731971  4.751474   0.003262   0.002757\n",
       "5719  10675  0.731972  4.751415   0.003188   0.002744\n",
       "5720  10676  0.731970  4.751394   0.003150   0.002731\n",
       "5721  10680  0.731962  4.751364   0.003025   0.002757\n",
       "5722  10684  0.731957  4.751355   0.002968   0.002763\n",
       "\n",
       "[5723 rows x 5 columns]"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012543999999999997"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.294*0.0012+0.330*0.001+0.172*0.0019+0.204*0.0012\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['CIEX'] = data0['CIEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(\"data/sub2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式來囉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = joblib.load('data/X_train.pkl')\n",
    "y = joblib.load('data/y_train.pkl')\n",
    "\n",
    "X_test = joblib.load('data/X_test.pkl')\n",
    "# y_test = joblib.load('data/y_test.pkl')\n",
    "# feat_select1_1 = joblib.load(f'saved_model_CIEX/feat_columns__stacking1.pkl')\n",
    "\n",
    "X.drop(3231, inplace = True)\n",
    "X.reset_index(drop=True, inplace = True)\n",
    "y.drop(3231, inplace = True)\n",
    "y.reset_index(drop=True, inplace = True)\n",
    "\n",
    "X_train = X[select_feat].to_numpy()\n",
    "X_test = X_test[select_feat].to_numpy()\n",
    "\n",
    "y_train1 = y['CIEX'].to_numpy()\n",
    "y_train2 = y['CIEY'].to_numpy()\n",
    "y_train3 = y['CIEX_DIFF'].to_numpy()\n",
    "y_train4 = y['CIEY_DIFF'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.13888902, 3.13921724, 3.13925988, ..., 0.73267211, 0.7327086 ,\n",
       "       0.73278424])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027015369661434305\n"
     ]
    }
   ],
   "source": [
    "model1 = StackingRegressor(\n",
    " estimators=estimators1,\n",
    "        final_estimator=RandomForestRegressor(n_estimators=250, max_depth=7, min_samples_split=2))\n",
    "\n",
    "model1.fit(X_train, y_train1)\n",
    "\n",
    "pr_tr = model1.predict(X_train)\n",
    "print(sum(np.abs(pr_tr - y_train1))/pr_tr.shape[0])\n",
    "\n",
    "# joblib.dump(model1, f'try2/CIEX.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.306122448979592e-05"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0000156/0.294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
